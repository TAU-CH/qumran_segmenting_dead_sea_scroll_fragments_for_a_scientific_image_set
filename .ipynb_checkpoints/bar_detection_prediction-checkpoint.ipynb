{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a51bce-a3c5-4e01-91f5-d731b8a2c3fe",
   "metadata": {},
   "source": [
    "## Inference on IAA images of Dead Sea Scrolls to detect the bars\n",
    "This notebook uses the trained model to detect bars in IAA images of the Dead Sea Scrolls. The detected bars are can be returned as a list of bounding boxes or visualized drawn bounding boxes around them on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f5469-8b09-463f-8099-aeedc181d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import torch\n",
    "import detectron2\n",
    "import json\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.model_zoo import model_zoo\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e483891-9769-4972-954b-199bf514c876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_get_cfg():\n",
    "    '''\n",
    "    Loads the Faster R-CNN configuration file from the model zoo, merges it with additional settings specific to the bar \n",
    "    detection, and returns the resulting configuration as a ConfigNode object.\n",
    "    \n",
    "    Returns:\n",
    "        ConfigNode: A ConfigNode object containing the configuration settings for the Faster R-CNN model.\n",
    "    '''\n",
    "    cfg = get_cfg()\n",
    "    # merge in configuration file for model\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    # adjust configuration settings for bar detection\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "    cfg.DATALOADER.NUM_WORKERS = 2\n",
    "    cfg.TEST.DETECTIONS_PER_IMAGE = 5\n",
    "    return cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1983f6ec-1253-47cf-9ba9-376e110643de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(image_path, model_path, threshold=0.90):\n",
    "    '''\n",
    "    Detects objects in an image using a specified model and returns the bounding boxes as a list.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): The path to the image file.\n",
    "        model_path (str): The path to the trained model file.\n",
    "        threshold (float, optional): The confidence threshold above which to consider an object detected. Defaults to 0.90.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of bounding boxes for the detected objects. Each bounding box is represented as a list of four floats \n",
    "              corresponding to the (x1, y1, x2, y2) coordinates of the top-left and height and width of the bounding box.\n",
    "    '''\n",
    "    setup_logger()\n",
    "    \n",
    "    # Get configuration settings for Faster R-CNN model specific to bar detection\n",
    "    bar_cfg = bar_get_cfg()\n",
    "    \n",
    "    # Set threshold for the model\n",
    "    bar_cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = threshold\n",
    "    \n",
    "    # Set path to the model\n",
    "    bar_cfg.MODEL.WEIGHTS = model_path\n",
    "    \n",
    "    # Create predictor object with the updated configuration settings\n",
    "    predictor = DefaultPredictor(bar_cfg)\n",
    "    \n",
    "    # Load image and use predictor to detect objects within the image\n",
    "    im = cv2.imread(image_path)\n",
    "    outputs = predictor(im)\n",
    "    \n",
    "    # Extract bounding boxes of detected objects and return as a list\n",
    "    bounding_boxes = []\n",
    "    for box in outputs[\"instances\"].pred_boxes.tensor.tolist():\n",
    "        bounding_boxes.append(box)\n",
    "    return bounding_boxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc7424e-f484-4006-8e17-be33189233a2",
   "metadata": {},
   "source": [
    "### Example using of detect_objects() function\n",
    "This function uses the trained model stored in model_path to detect objects in the image located at image_path. The threshold argument specifies the confidence threshold for detection, with the default value set to 0.90.\n",
    "\n",
    "The function returns a list of bounding boxes of detected objects in the image, where each bounding box is represented as a list of four coordinates: (x1, y1, h, w). These coordinates correspond to the top left x, y coordinates and height and width of the bounding box, respectively. The bounding_boxes variable stores this list of detected bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c7064e-93f4-41c0-936d-9e94a3a2fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_boxes = detect_objects(image_path = \"bar_data/test_images/1094_2_recto_color.jpg\", model_path = \"output/model_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037486f1-edce-434d-8edf-539007cab47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98145365-6d61-45c5-8458-4d31f2f53fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_objects(image_path, model_path, threshold=0.90):\n",
    "    '''\n",
    "    Displays an image with bounding boxes drawn around any detected objects.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The path to the image to be processed.\n",
    "        model_path (str): The path to the trained model to use for object detection.\n",
    "        threshold (float, optional): The minimum confidence threshold for detected objects. Default is 0.90.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays the image with bounding boxes drawn around any detected objects.\n",
    "    '''\n",
    "    setup_logger()\n",
    "    # Get configuration for bar detection\n",
    "    bar_cfg = bar_get_cfg()\n",
    "    # Set threshold for model\n",
    "    bar_cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = threshold\n",
    "    # Load trained weights\n",
    "    bar_cfg.MODEL.WEIGHTS = model_path\n",
    "    # Create predictor\n",
    "    predictor = DefaultPredictor(bar_cfg)\n",
    "    # Load image\n",
    "    im = cv2.imread(image_path)\n",
    "    # Run inference on image\n",
    "    outputs = predictor(im)\n",
    "    # Visualize predictions\n",
    "    v = Visualizer(im,\n",
    "                   metadata=bar_test_metadata, \n",
    "                   scale=1, \n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    # Display image with bounding boxes\n",
    "    plt.imshow(out.get_image()[:, :, ::-1])\n",
    "    plt.axis('off')\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e59b46-4f28-4067-92ce-a7e7a36dd16a",
   "metadata": {},
   "source": [
    "### Example using of show_objects() function\n",
    "This function takes an image path and a trained model path as inputs, along with an optional threshold value. It loads the specified image and trained model, runs inference on the image using the specified model, and then displays the image with bounding boxes drawn around any detected objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef6fc47-2b3d-4cd6-ba40-c831c7233e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_objects(image_path = \"bar_data/test_images/1094_2_recto_color.jpg\", model_path = \"output/model_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228a6ac1-c2eb-4f5d-963c-9c318aa75e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_bbox_size(outputs, increase_pixels, image_shape):\n",
    "    '''\n",
    "    Increase the size of the bounding boxes in the given outputs.\n",
    "    Args:\n",
    "        outputs (dict): A dictionary containing the model's predictions.\n",
    "        increase_pixels (int): The number of pixels to add to the edges of each bounding box.\n",
    "        image_shape (tuple): A tuple containing the dimensions of the image in (height, width) format.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the modified bounding boxes.\n",
    "    '''\n",
    "    # Access the bounding boxes from the outputs\n",
    "    bboxes = outputs['instances'].pred_boxes.tensor.clone()\n",
    "    # Increase the size of the bounding boxes\n",
    "    bboxes[:, 0] -= increase_pixels # xmin\n",
    "    bboxes[:, 1] -= increase_pixels # ymin\n",
    "    bboxes[:, 2] += increase_pixels*2 # xmax\n",
    "    bboxes[:, 3] += increase_pixels*2 # ymax\n",
    "    # Check if any coordinates are outside of the image bounds\n",
    "    bboxes[:, 0] = torch.clamp(bboxes[:, 0], min=0) # xmin\n",
    "    bboxes[:, 1] = torch.clamp(bboxes[:, 1], min=0) # ymin\n",
    "    bboxes[:, 2] = torch.clamp(bboxes[:, 2], max=image_shape[1]) # xmax\n",
    "    bboxes[:, 3] = torch.clamp(bboxes[:, 3], max=image_shape[0]) # ymax\n",
    "    # Update the bounding boxes in the outputs\n",
    "    outputs['instances'].pred_boxes.tensor = bboxes\n",
    "    # Return the modified outputs\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b224639-8df5-46ee-9776-799e96800a99",
   "metadata": {},
   "source": [
    "### Inference on full set of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c15921-2594-4114-9894-2e7c41d64a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the detection threshold and model path\n",
    "threshold = 0.95\n",
    "model_path = 'output/model_final.pth'\n",
    "\n",
    "# Initialize the object detection model\n",
    "setup_logger()\n",
    "bar_cfg = bar_get_cfg()\n",
    "bar_test_metadata = MetadataCatalog.get(\"bar_test\")\n",
    "bar_cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = threshold\n",
    "bar_cfg.MODEL.WEIGHTS = model_path\n",
    "predictor = DefaultPredictor(bar_cfg)\n",
    "\n",
    "# Create directory for the visualized outputs\n",
    "if not os.path.exists('output/visualized_predictions'):\n",
    "    os.makedirs('output/visualized_predictions')\n",
    "\n",
    "# Create an empty COCO annotations dictionary\n",
    "coco = {\"images\": [], \"annotations\": [], \"categories\": []}\n",
    "\n",
    "# Iterate through the images\n",
    "for file_name in os.listdir(\"bar_data/test_images\"):\n",
    "    # Load the image\n",
    "    img = cv2.imread(f\"bar_data/test_images/{file_name}\")\n",
    "    # Predict the bounding boxes\n",
    "    outputs = predictor(img)\n",
    "    # Increase bbox size by at each direction\n",
    "    outputs = increase_bbox_size(outputs, 30, img.shape[:2])\n",
    "    # Save the visualization\n",
    "    v = Visualizer(img,\n",
    "                   metadata=bar_test_metadata, \n",
    "                   scale=1, \n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2.imwrite('output/visualized_predictions/'+file_name, out.get_image())\n",
    "    # Get the predicted bounding boxes\n",
    "    bboxes = outputs[\"instances\"].pred_boxes.tensor.tolist()\n",
    "    # Get the predicted class labels\n",
    "    labels = outputs[\"instances\"].pred_classes.tolist()\n",
    "    # Add the image to the COCO annotations dictionary\n",
    "    coco[\"images\"].append({\"file_name\": file_name, \"id\": len(coco[\"images\"]) + 1})\n",
    "    # Add the predicted bounding boxes to the COCO annotations dictionary\n",
    "    for bbox, label in zip(bboxes, labels):\n",
    "        coco[\"annotations\"].append({\"image_id\": len(coco[\"images\"]), \"bbox\": bbox, \"category_id\": label})\n",
    "    # Add the category labels to the COCO annotations dictionary\n",
    "    if len(coco[\"categories\"]) == 0:\n",
    "        for label in set(labels):\n",
    "            coco[\"categories\"].append({\"id\": label, \"name\": f\"class_{label}\"})\n",
    "\n",
    "# Save the COCO annotations to a json file\n",
    "with open(\"output/test_predictions.json\", \"w\") as f:\n",
    "    json.dump(coco, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44f5405-19dc-4b01-9c58-2070497bbca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
